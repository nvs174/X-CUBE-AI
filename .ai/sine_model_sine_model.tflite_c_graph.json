{
    "activations": {
        "heap_overlay_pool": {
            "activation_alignment": 4,
            "buffer_data_size": 0,
            "buffer_offsets": [
                {
                    "buffer_name": "serving_default_keras_tensor_200_output_array",
                    "offset": 60,
                    "size": 4
                },
                {
                    "buffer_name": "gemm_0_output_array",
                    "offset": 64,
                    "size": 64
                },
                {
                    "buffer_name": "nl_0_nl_output_array",
                    "offset": 64,
                    "size": 64
                },
                {
                    "buffer_name": "gemm_1_output_array",
                    "offset": 0,
                    "size": 64
                },
                {
                    "buffer_name": "nl_1_nl_output_array",
                    "offset": 64,
                    "size": 64
                },
                {
                    "buffer_name": "gemm_2_output_array",
                    "offset": 0,
                    "size": 4
                }
            ],
            "data_alignment": 4,
            "pool_id": 0,
            "pool_size": -1,
            "used_size": 128
        }
    },
    "activations_alignment": 4,
    "arguments": "analyze --target stm32f4 --name sine_model -m C:/Users/CHUWI/Downloads/sine_model.tflite --compression none --verbosity 1 --workspace C:/Users/CHUWI/AppData/Local/Temp/mxAI_workspace9007877089720010161891805734311770 --output C:/Users/CHUWI/.stm32cubemx/sine_model_output",
    "c_activations_count": 1,
    "c_arrays": [
        {
            "c_bits": 32,
            "c_id": 0,
            "c_mem_pool": "weights",
            "c_size_in_byte": 64,
            "c_type": "const float",
            "format": "float",
            "is_const": true,
            "mem_pool": "weights",
            "n_items": 16,
            "name": "gemm_0_bias_array",
            "offset": 64,
            "scale": [],
            "size": 16,
            "tensors": [
                {
                    "name": "gemm_0_bias",
                    "shape": [
                        16
                    ]
                }
            ],
            "zeropoint": [],
            "zeros": 0
        },
        {
            "c_bits": 32,
            "c_id": 1,
            "c_mem_pool": "**default**",
            "c_size_in_byte": 64,
            "c_type": "float",
            "format": "float",
            "is_const": false,
            "mem_pool": "activations",
            "n_items": 16,
            "name": "gemm_0_output_array",
            "offset": 64,
            "scale": [],
            "size": 16,
            "tensors": [
                {
                    "name": "gemm_0_output",
                    "shape": [
                        16
                    ]
                }
            ],
            "zeropoint": []
        },
        {
            "c_bits": 32,
            "c_id": 2,
            "c_mem_pool": "weights",
            "c_size_in_byte": 64,
            "c_type": "const float",
            "format": "float",
            "is_const": true,
            "mem_pool": "weights",
            "n_items": 16,
            "name": "gemm_0_weights_array",
            "offset": 0,
            "scale": [],
            "size": 16,
            "tensors": [
                {
                    "name": "gemm_0_weights",
                    "shape": [
                        16,
                        1
                    ]
                }
            ],
            "zeropoint": [],
            "zeros": 0
        },
        {
            "c_bits": 32,
            "c_id": 3,
            "c_mem_pool": "weights",
            "c_size_in_byte": 64,
            "c_type": "const float",
            "format": "float",
            "is_const": true,
            "mem_pool": "weights",
            "n_items": 16,
            "name": "gemm_1_bias_array",
            "offset": 1152,
            "scale": [],
            "size": 16,
            "tensors": [
                {
                    "name": "gemm_1_bias",
                    "shape": [
                        16
                    ]
                }
            ],
            "zeropoint": [],
            "zeros": 0
        },
        {
            "c_bits": 32,
            "c_id": 4,
            "c_mem_pool": "**default**",
            "c_size_in_byte": 64,
            "c_type": "float",
            "format": "float",
            "is_const": false,
            "mem_pool": "activations",
            "n_items": 16,
            "name": "gemm_1_output_array",
            "offset": 0,
            "scale": [],
            "size": 16,
            "tensors": [
                {
                    "name": "gemm_1_output",
                    "shape": [
                        16
                    ]
                }
            ],
            "zeropoint": []
        },
        {
            "c_bits": 32,
            "c_id": 5,
            "c_mem_pool": "weights",
            "c_size_in_byte": 1024,
            "c_type": "const float",
            "format": "float",
            "is_const": true,
            "mem_pool": "weights",
            "n_items": 256,
            "name": "gemm_1_weights_array",
            "offset": 128,
            "scale": [],
            "size": 256,
            "tensors": [
                {
                    "name": "gemm_1_weights",
                    "shape": [
                        16,
                        16
                    ]
                }
            ],
            "zeropoint": [],
            "zeros": 0
        },
        {
            "c_bits": 32,
            "c_id": 6,
            "c_mem_pool": "weights",
            "c_size_in_byte": 4,
            "c_type": "const float",
            "format": "float",
            "is_const": true,
            "mem_pool": "weights",
            "n_items": 1,
            "name": "gemm_2_bias_array",
            "offset": 1280,
            "scale": [],
            "size": 1,
            "tensors": [
                {
                    "name": "gemm_2_bias",
                    "shape": [
                        1
                    ]
                }
            ],
            "zeropoint": [],
            "zeros": 0
        },
        {
            "c_bits": 32,
            "c_id": 7,
            "c_mem_pool": "**default**",
            "c_size_in_byte": 4,
            "c_type": "float",
            "format": "float",
            "io_type": "output",
            "is_const": false,
            "mem_pool": "activations",
            "n_items": 1,
            "name": "gemm_2_output_array",
            "offset": 0,
            "scale": [],
            "size": 1,
            "tensors": [
                {
                    "name": "gemm_2_output",
                    "shape": [
                        1
                    ]
                }
            ],
            "zeropoint": []
        },
        {
            "c_bits": 32,
            "c_id": 8,
            "c_mem_pool": "weights",
            "c_size_in_byte": 64,
            "c_type": "const float",
            "format": "float",
            "is_const": true,
            "mem_pool": "weights",
            "n_items": 16,
            "name": "gemm_2_weights_array",
            "offset": 1216,
            "scale": [],
            "size": 16,
            "tensors": [
                {
                    "name": "gemm_2_weights",
                    "shape": [
                        1,
                        16
                    ]
                }
            ],
            "zeropoint": [],
            "zeros": 0
        },
        {
            "c_bits": 32,
            "c_id": 9,
            "c_mem_pool": "**default**",
            "c_size_in_byte": 64,
            "c_type": "float",
            "format": "float",
            "is_const": false,
            "mem_pool": "activations",
            "n_items": 16,
            "name": "nl_0_nl_output_array",
            "offset": 64,
            "scale": [],
            "size": 16,
            "tensors": [
                {
                    "name": "nl_0_nl_output",
                    "shape": [
                        16
                    ]
                }
            ],
            "zeropoint": []
        },
        {
            "c_bits": 32,
            "c_id": 10,
            "c_mem_pool": "**default**",
            "c_size_in_byte": 64,
            "c_type": "float",
            "format": "float",
            "is_const": false,
            "mem_pool": "activations",
            "n_items": 16,
            "name": "nl_1_nl_output_array",
            "offset": 64,
            "scale": [],
            "size": 16,
            "tensors": [
                {
                    "name": "nl_1_nl_output",
                    "shape": [
                        16
                    ]
                }
            ],
            "zeropoint": []
        },
        {
            "c_bits": 32,
            "c_id": 11,
            "c_mem_pool": "**default**",
            "c_size_in_byte": 4,
            "c_type": "float",
            "format": "float",
            "io_type": "input",
            "is_const": false,
            "mem_pool": "activations",
            "n_items": 1,
            "name": "serving_default_keras_tensor_200_output_array",
            "offset": 60,
            "scale": [],
            "size": 1,
            "tensors": [
                {
                    "name": "serving_default_keras_tensor_200_output",
                    "shape": [
                        1
                    ]
                }
            ],
            "zeropoint": []
        }
    ],
    "c_arrays_n": 12,
    "c_layers": [
        {
            "c_forward": [
                "forward_dense"
            ],
            "c_id": 0,
            "is_wrapped": "",
            "layer_type": "Dense",
            "m_id": 0,
            "macc": 32,
            "name": "gemm_0",
            "op_by_type": {
                "smul_f32_f32": 32
            },
            "rom": 128,
            "tensors": {
                "inputs": [
                    "serving_default_keras_tensor_200_output"
                ],
                "outputs": [
                    "gemm_0_output"
                ],
                "scratchs": [],
                "weights": [
                    "gemm_0_weights",
                    "gemm_0_bias"
                ]
            },
            "weight_sparsity": [
                0.0,
                32,
                0
            ]
        },
        {
            "c_forward": [
                "forward_relu"
            ],
            "c_id": 1,
            "is_wrapped": "",
            "layer_type": "Nonlinearity",
            "m_id": 0,
            "macc": 16,
            "name": "nl_0_nl",
            "op_by_type": {
                "op_f32_f32": 16
            },
            "rom": 0,
            "tensors": {
                "inputs": [
                    "gemm_0_output"
                ],
                "outputs": [
                    "nl_0_nl_output"
                ],
                "scratchs": [],
                "weights": []
            },
            "weight_sparsity": [
                0.0,
                1,
                0
            ]
        },
        {
            "c_forward": [
                "forward_dense"
            ],
            "c_id": 2,
            "is_wrapped": "",
            "layer_type": "Dense",
            "m_id": 1,
            "macc": 272,
            "name": "gemm_1",
            "op_by_type": {
                "smul_f32_f32": 272
            },
            "rom": 1088,
            "tensors": {
                "inputs": [
                    "nl_0_nl_output"
                ],
                "outputs": [
                    "gemm_1_output"
                ],
                "scratchs": [],
                "weights": [
                    "gemm_1_weights",
                    "gemm_1_bias"
                ]
            },
            "weight_sparsity": [
                0.0,
                272,
                0
            ]
        },
        {
            "c_forward": [
                "forward_relu"
            ],
            "c_id": 3,
            "is_wrapped": "",
            "layer_type": "Nonlinearity",
            "m_id": 1,
            "macc": 16,
            "name": "nl_1_nl",
            "op_by_type": {
                "op_f32_f32": 16
            },
            "rom": 0,
            "tensors": {
                "inputs": [
                    "gemm_1_output"
                ],
                "outputs": [
                    "nl_1_nl_output"
                ],
                "scratchs": [],
                "weights": []
            },
            "weight_sparsity": [
                0.0,
                1,
                0
            ]
        },
        {
            "c_forward": [
                "forward_dense"
            ],
            "c_id": 4,
            "is_wrapped": "",
            "layer_type": "Dense",
            "m_id": 2,
            "macc": 17,
            "name": "gemm_2",
            "op_by_type": {
                "smul_f32_f32": 17
            },
            "rom": 68,
            "tensors": {
                "inputs": [
                    "nl_1_nl_output"
                ],
                "outputs": [
                    "gemm_2_output"
                ],
                "scratchs": [],
                "weights": [
                    "gemm_2_weights",
                    "gemm_2_bias"
                ]
            },
            "weight_sparsity": [
                0.0,
                17,
                0
            ]
        }
    ],
    "c_name": "sine_model",
    "c_nodes_n": 5,
    "c_weights_count": 1,
    "c_weights_header": 0,
    "compilation_options": {
        "compression": "none",
        "optimization": "balanced",
        "options": [
            "allocate-inputs",
            "allocate-outputs"
        ]
    },
    "data_alignment": 4,
    "date_time": "2025-03-27T19:12:49+0300",
    "inputs": [
        "serving_default_keras_tensor_200_output"
    ],
    "macc": 353,
    "memory_footprint": {
        "activations": 128,
        "io": [
            0,
            0
        ],
        "kernel_flash": 8848,
        "kernel_ram": 1812,
        "series": "stm32f4",
        "target": "stm32f4",
        "toolchain": "arm-none-eabi-gcc (GNU Tools for STM32 13.3.rel1.20240926-1715) 13.3.1 20240614",
        "toolchain_flash": 0,
        "toolchain_ram": 0,
        "weights": 1284
    },
    "memory_pools": [],
    "model_fmt": "float",
    "model_name": "sine_model",
    "model_signature": "0x8258fa89eb5c479a0abba3be7fb7a0d0",
    "outputs": [
        "gemm_2_output"
    ],
    "st_ai_version": "2.0.0-20049",
    "tool_version": "2.0.0-20049",
    "type": "tflite",
    "version": "1.2",
    "weights": {
        "weights_array": {
            "buffer_data_size": 1284,
            "buffer_offsets": [
                {
                    "buffer_name": "gemm_0_weights_array",
                    "offset": 0,
                    "size": 64
                },
                {
                    "buffer_name": "gemm_0_bias_array",
                    "offset": 64,
                    "size": 64
                },
                {
                    "buffer_name": "gemm_1_weights_array",
                    "offset": 128,
                    "size": 1024
                },
                {
                    "buffer_name": "gemm_1_bias_array",
                    "offset": 1152,
                    "size": 64
                },
                {
                    "buffer_name": "gemm_2_weights_array",
                    "offset": 1216,
                    "size": 64
                },
                {
                    "buffer_name": "gemm_2_bias_array",
                    "offset": 1280,
                    "size": 4
                }
            ],
            "pool_size": -1,
            "used_size": 1284
        }
    }
}